from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any
import pandas as pd
import numpy as np
import pymysql
import pickle
import os
import json
from datetime import datetime, timedelta
import xgboost as xgb
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import logging
from pathlib import Path
import asyncio
from contextlib import asynccontextmanager
from dotenv import load_dotenv
import math
import warnings
import re
warnings.filterwarnings('ignore')

# Load environment variables
load_dotenv()

# Logging setup
logging.basicConfig(
    level=logging.INFO if os.getenv('DEBUG', 'false').lower() == 'true' else logging.WARNING,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# FastAPI app initialization
app = FastAPI(
    title="Energy Consumption Prediction API",
    description="Machine Learning API for predicting energy consumption (Electricity, Water, Natural Gas, Paper)",
    version="1.0.0"
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Database connection config from environment variables
DB_CONFIG = {
    'host': os.getenv('DB_HOST', 'localhost'),
    'port': int(os.getenv('DB_PORT', 3306)),
    'user': os.getenv('DB_USER', 'root'),
    'password': os.getenv('DB_PASSWORD', ''),
    'database': os.getenv('DB_NAME', 'ENVIROMENT'),
    'ssl': {'ssl_mode': os.getenv('DB_SSL_MODE', 'DISABLED')},
    'cursorclass': pymysql.cursors.DictCursor
}

# Model storage paths from environment
MODELS_DIR = Path(os.getenv('MODELS_DIR', 'models'))
MODELS_DIR.mkdir(exist_ok=True)
LOGS_DIR = Path(os.getenv('LOGS_DIR', 'logs'))
LOGS_DIR.mkdir(exist_ok=True)

# Environment info
ENVIRONMENT = os.getenv('ENVIRONMENT', 'development')
DEBUG = os.getenv('DEBUG', 'false').lower() == 'true'

logger.info(f"Starting API in {ENVIRONMENT} mode, Debug: {DEBUG}")
logger.info(f"Database Host: {DB_CONFIG['host']}:{DB_CONFIG['port']}")
logger.info(f"Models Directory: {MODELS_DIR}")

# Resource types and their database tables
RESOURCE_MAPPING = {
    'electricity': 'Electrics',
    'water': 'Waters',
    'naturalgas': 'NaturalGas',
    'paper': 'Papers'
}

# Model types
MODEL_TYPES = ['rf', 'xgb', 'gb']
ENSEMBLE_TYPES = ['rf_gb', 'rf_xgb', 'gb_xgb', 'rf_gb_xgb']

# Utility functions
def safe_float_conversion(value):
    """Safely convert values to JSON-serializable floats"""
    if value is None:
        return None
    if isinstance(value, (int, float)):
        if math.isnan(value) or math.isinf(value):
            return 0.0
        # Don't round very small positive values to 0
        if abs(value) < 1e-10:
            return 0.0
        return float(value)
    try:
        float_val = float(value)
        if math.isnan(float_val) or math.isinf(float_val):
            return 0.0
        if abs(float_val) < 1e-10:
            return 0.0
        return float_val
    except (ValueError, TypeError):
        return 0.0

def safe_dict_conversion(data_dict):
    """Safely convert dictionary values for JSON serialization"""
    safe_dict = {}
    for key, value in data_dict.items():
        if isinstance(value, dict):
            safe_dict[key] = safe_dict_conversion(value)
        elif isinstance(value, (list, tuple)):
            safe_dict[key] = [safe_float_conversion(v) if isinstance(v, (int, float)) else v for v in value]
        else:
            safe_dict[key] = safe_float_conversion(value) if isinstance(value, (int, float)) else value
    return safe_dict

def clean_feature_names(feature_names):
    """Clean feature names for XGBoost compatibility - SIMPLIFIED AND CONSISTENT"""
    cleaned_names = []
    for name in feature_names:
        # Convert to string and handle basic cleaning
        clean_name = str(name)
        # Replace any non-alphanumeric characters with underscore
        clean_name = re.sub(r'[^a-zA-Z0-9]', '_', clean_name)
        # Remove multiple underscores
        clean_name = re.sub(r'_+', '_', clean_name)
        # Remove leading/trailing underscores
        clean_name = clean_name.strip('_')
        
        # Ensure it doesn't start with a number
        if clean_name and clean_name[0].isdigit():
            clean_name = 'f_' + clean_name
        
        # Fallback if empty
        if not clean_name:
            clean_name = f'feature_{len(cleaned_names)}'
        
        cleaned_names.append(clean_name)
    
    return cleaned_names

# Pydantic models with fixed namespace conflicts
class TrainRequest(BaseModel):
    model_config = {"protected_namespaces": ()}
    resource_type: str = Field(..., description="Resource type: electricity, water, naturalgas, paper")
    building_id: Optional[str] = Field("0", description="Building ID (0 for all buildings, or UUID string)")
    model_types: Optional[List[str]] = Field(default_factory=lambda: MODEL_TYPES,
                                           description="Model types to train")
    ensemble_types: Optional[List[str]] = Field(default_factory=lambda: ENSEMBLE_TYPES,
                                              description="Ensemble types to create")

class PredictRequest(BaseModel):
    model_config = {"protected_namespaces": ()}
    resource_type: str = Field(..., description="Resource type")
    building_id: Optional[str] = Field("0", description="Building ID (0 for all buildings, or UUID string)")
    model_type: str = Field(..., description="Model type or ensemble type")
    months_ahead: Optional[int] = Field(12, description="Number of months to predict")

class TrainResponse(BaseModel):
    model_config = {"protected_namespaces": ()}
    success: bool
    message: str
    models_trained: List[str]
    metrics: Dict[str, Any]
    data_info: Dict[str, Any]

class PredictResponse(BaseModel):
    model_config = {"protected_namespaces": ()}
    success: bool
    predictions: List[Dict[str, Any]]
    model_info: Dict[str, Any]

class ModelInfo(BaseModel):
    model_config = {"protected_namespaces": ()}
    resource_type: str
    building_id: str
    model_type: str
    trained_at: str
    metrics: Dict[str, float]
    data_points: int

# Database connection helper
def get_db_connection():
    try:
        connection = pymysql.connect(**DB_CONFIG)
        return connection
    except Exception as e:
        logger.error(f"Database connection error: {e}")
        raise HTTPException(status_code=500, detail="Database connection failed")

# Feature engineering functions
class FeatureEngineer:
    @staticmethod
    def create_features(df: pd.DataFrame, resource_type: str) -> pd.DataFrame:
        """Create enhanced features specific to resource type"""
        df = df.copy()
        
        # Ensure Date column exists and is datetime
        if 'Date' not in df.columns:
            logger.error("Date column missing in create_features input")
            raise ValueError("Date column required for feature creation")
        
        # Convert Date to datetime if it's not already
        if not pd.api.types.is_datetime64_any_dtype(df['Date']):
            df['Date'] = pd.to_datetime(df['Date'])
        
        # Basic time features
        df['Year'] = df['Date'].dt.year
        df['Month'] = df['Date'].dt.month
        df['Quarter'] = df['Date'].dt.quarter
        df['YearMonth'] = df['Date'].dt.strftime('%Y-%m')
        
        # Enhanced seasonal features based on resource type
        if resource_type == 'electricity':
            df['IsHeatingMonth'] = df['Month'].apply(lambda x: 1 if x in [1, 2, 3, 11, 12] else 0)
            df['IsCoolingMonth'] = df['Month'].apply(lambda x: 1 if x in [6, 7, 8, 9] else 0)
            df['IsHolidayMonth'] = df['Month'].apply(lambda x: 1 if x in [7, 8] else 0)
            df['IsPeakMonth'] = df['Month'].apply(lambda x: 1 if x in [1, 2, 7, 8, 12] else 0)
        elif resource_type == 'naturalgas':
            df['IsHeatingMonth'] = df['Month'].apply(lambda x: 1 if x in [1, 2, 3, 10, 11, 12] else 0)
            df['IsNonHeatingMonth'] = df['Month'].apply(lambda x: 1 if x in [5, 6, 7, 8, 9] else 0)
            df['IsTransitionMonth'] = df['Month'].apply(lambda x: 1 if x in [4, 10] else 0)
            df['IsPeakHeatingMonth'] = df['Month'].apply(lambda x: 1 if x in [1, 2, 12] else 0)
        elif resource_type == 'paper':
            df['IsAcademicMonth'] = df['Month'].apply(lambda x: 1 if x in [9, 10, 11, 12, 1, 2, 3, 4, 5] else 0)
            df['IsHolidayMonth'] = df['Month'].apply(lambda x: 1 if x in [6, 7, 8] else 0)
            df['IsExamMonth'] = df['Month'].apply(lambda x: 1 if x in [1, 5, 6] else 0)
            df['IsStartSemester'] = df['Month'].apply(lambda x: 1 if x in [9, 2] else 0)
        elif resource_type == 'water':
            df['IsHolidayMonth'] = df['Month'].apply(lambda x: 1 if x in [7, 8] else 0)
            df['IsSummerMonth'] = df['Month'].apply(lambda x: 1 if x in [6, 7, 8, 9] else 0)
        
        # Enhanced common features
        df['Season'] = df['Month'].apply(
            lambda x: 0 if x in [12, 1, 2] else 1 if x in [3, 4, 5] else 2 if x in [6, 7, 8] else 3
        )
        
        # Enhanced Fourier features for better seasonality capture
        df['SinMonth'] = np.sin(2 * np.pi * df['Month'] / 12)
        df['CosMonth'] = np.cos(2 * np.pi * df['Month'] / 12)
        df['SinQuarter'] = np.sin(2 * np.pi * df['Quarter'] / 4)
        df['CosQuarter'] = np.cos(2 * np.pi * df['Quarter'] / 4)
        df['SinSemester'] = np.sin(2 * np.pi * df['Month'] / 6)
        df['CosSemester'] = np.cos(2 * np.pi * df['Month'] / 6)
        
        # Enhanced trend features
        min_year = df['Year'].min()
        df['YearTrend'] = df['Year'] - min_year
        df['YearTrendSq'] = df['YearTrend'] ** 2
        df['MonthsFromStart'] = (df['Year'] - min_year) * 12 + df['Month'] - df['Month'].iloc[0]
        
        # Only create lag and rolling features if Usage column has values
        if 'Usage' in df.columns and not df['Usage'].isna().all():
            # Enhanced lag features
            for lag in [1, 2, 3, 6, 12, 24]:
                if len(df) > lag:
                    df[f'Usage_Lag{lag}'] = df['Usage'].shift(lag)
            
            # Enhanced rolling statistics
            for window in [3, 6, 12]:
                if len(df) >= window:
                    df[f'RollingMean{window}'] = df['Usage'].rolling(window=window, min_periods=1).mean()
                    df[f'RollingStd{window}'] = df['Usage'].rolling(window=window, min_periods=1).std()
                    df[f'RollingMin{window}'] = df['Usage'].rolling(window=window, min_periods=1).min()
                    df[f'RollingMax{window}'] = df['Usage'].rolling(window=window, min_periods=1).max()
            
            # Enhanced change rates
            df['MonthlyChange'] = df['Usage'].pct_change(1).fillna(0)
            df['YearlyChange'] = df['Usage'].pct_change(12).fillna(0)
            df['QuarterlyChange'] = df['Usage'].pct_change(3).fillna(0)
            
            # Seasonal decomposition features
            monthly_avg = df.groupby('Month')['Usage'].mean()
            overall_avg = df['Usage'].mean()
            if overall_avg > 0:
                month_indexes = monthly_avg / overall_avg
                df['SeasonalIndex'] = df['Month'].map(month_indexes)
                df['SeasonalStrength'] = np.abs(df['SeasonalIndex'] - 1.0)
            else:
                df['SeasonalIndex'] = 1.0
                df['SeasonalStrength'] = 0.0
            
            # Moving averages for trend detection
            df['MA_Short'] = df['Usage'].rolling(window=3, min_periods=1).mean()
            df['MA_Long'] = df['Usage'].rolling(window=12, min_periods=1).mean()
            df['TrendIndicator'] = (df['MA_Short'] - df['MA_Long']) / df['MA_Long'].replace(0, 1)
            
            # Fill NaN values in lag and rolling features
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            for col in numeric_cols:
                if col != 'Usage':
                    df[col] = df[col].fillna(method='ffill').fillna(method='bfill').fillna(0)
        else:
            # Initialize features with zeros for future predictions
            for lag in [1, 2, 3, 6, 12, 24]:
                df[f'Usage_Lag{lag}'] = 0
            
            for window in [3, 6, 12]:
                df[f'RollingMean{window}'] = 0
                df[f'RollingStd{window}'] = 0
                df[f'RollingMin{window}'] = 0
                df[f'RollingMax{window}'] = 0
            
            df['MonthlyChange'] = 0
            df['YearlyChange'] = 0
            df['QuarterlyChange'] = 0
            df['SeasonalIndex'] = 1.0
            df['SeasonalStrength'] = 0.0
            df['MA_Short'] = 0
            df['MA_Long'] = 0
            df['TrendIndicator'] = 0
        
        # Ensure no NaN values remain
        df = df.fillna(0)
        
        # Verify Date column is still present
        if 'Date' not in df.columns:
            logger.error("Date column lost during feature creation")
            raise ValueError("Date column lost during feature creation")
        
        return df
    
    @staticmethod
    def get_feature_columns(df: pd.DataFrame, resource_type: str) -> List[str]:
        """Get relevant feature columns for the resource type (excluding Date and Usage)"""
        base_features = ['Month', 'Year', 'Quarter', 'Season', 'SinMonth', 'CosMonth',
                        'SinQuarter', 'CosQuarter', 'SinSemester', 'CosSemester',
                        'YearTrend', 'YearTrendSq', 'MonthsFromStart', 'SeasonalIndex', 
                        'SeasonalStrength', 'TrendIndicator']
        
        # Add resource-specific features
        if resource_type == 'electricity':
            base_features.extend(['IsHeatingMonth', 'IsCoolingMonth', 'IsHolidayMonth', 'IsPeakMonth'])
        elif resource_type == 'naturalgas':
            base_features.extend(['IsHeatingMonth', 'IsNonHeatingMonth', 'IsTransitionMonth', 'IsPeakHeatingMonth'])
        elif resource_type == 'paper':
            base_features.extend(['IsAcademicMonth', 'IsHolidayMonth', 'IsExamMonth', 'IsStartSemester'])
        elif resource_type == 'water':
            base_features.extend(['IsHolidayMonth', 'IsSummerMonth'])
        
        # Add lag and rolling features that exist in the dataframe
        for col in df.columns:
            if any(pattern in col for pattern in ['Lag', 'Rolling', 'Change', 'MA_']):
                if col not in base_features:
                    base_features.append(col)
        
        # Return only features that actually exist in the dataframe, excluding Date and Usage
        return [col for col in base_features if col in df.columns and col not in ['Date', 'Usage']]

# Data loader with improved error handling
class DataLoader:
    @staticmethod
    def load_data(resource_type: str, building_id: str = "0") -> pd.DataFrame:
        """Load data from database with improved error handling"""
        table_name = RESOURCE_MAPPING.get(resource_type)
        if not table_name:
            raise ValueError(f"Invalid resource type: {resource_type}")
        
        connection = get_db_connection()
        
        try:
            cursor = connection.cursor()
            
            if building_id == "0":
                # All buildings - FIXED SQL query with proper GROUP BY
                query = f"""
                    SELECT
                        YEAR(`Date`) as Year,
                        MONTH(`Date`) as Month,
                        SUM(`Usage`) as `Usage`
                    FROM {table_name}
                    WHERE `Usage` > 0 
                        AND `Date` IS NOT NULL
                        AND `Usage` IS NOT NULL
                    GROUP BY YEAR(`Date`), MONTH(`Date`)
                    HAVING SUM(`Usage`) > 0
                    ORDER BY YEAR(`Date`), MONTH(`Date`)
                """
                logger.info(f"Executing aggregation query for all buildings: {query}")
                cursor.execute(query)
                logger.info(f"Loading aggregated data for all buildings from {table_name}")
            else:
                # Specific building - FIXED SQL query with proper GROUP BY
                query = f"""
                    SELECT 
                        BuildingId,
                        YEAR(`Date`) as Year,
                        MONTH(`Date`) as Month,
                        SUM(`Usage`) as `Usage`
                    FROM {table_name}
                    WHERE BuildingId = %s 
                        AND `Usage` > 0
                        AND `Date` IS NOT NULL
                        AND `Usage` IS NOT NULL
                    GROUP BY BuildingId, YEAR(`Date`), MONTH(`Date`)
                    HAVING SUM(`Usage`) > 0
                    ORDER BY YEAR(`Date`), MONTH(`Date`)
                """
                logger.info(f"Executing building-specific query: {query} with building_id: {building_id}")
                cursor.execute(query, (building_id,))
                logger.info(f"Loading data for building {building_id} from {table_name}")
            
            data = cursor.fetchall()
            logger.info(f"Raw data fetched: {len(data)} records")
            
            if not data:
                logger.error(f"No data found for resource_type: {resource_type}, building_id: {building_id}")
                raise ValueError(f"No data found for resource_type: {resource_type}, building_id: {building_id}")
            
            df = pd.DataFrame(data)
            logger.info(f"DataFrame created with {len(df)} rows and columns: {df.columns.tolist()}")
            
            # Data cleaning and conversion
            df['Usage'] = pd.to_numeric(df['Usage'], errors='coerce')
            
            # Create Date column from Year and Month
            df['Date'] = pd.to_datetime(df[['Year', 'Month']].assign(day=1))
            
            # Remove invalid data
            df = df.dropna(subset=['Usage', 'Date'])
            df = df[df['Usage'] > 0]  # Remove zero or negative usage
            
            logger.info(f"After cleaning: {len(df)} records")
            
            if df.empty:
                raise ValueError(f"No valid data after cleaning for resource_type: {resource_type}, building_id: {building_id}")
            
            # Sort by date
            df = df.sort_values('Date').reset_index(drop=True)
            
            logger.info(f"Loaded {len(df)} monthly records")
            logger.info(f"Date range: {df['Date'].min()} to {df['Date'].max()}")
            logger.info(f"Usage range: {df['Usage'].min()} to {df['Usage'].max()}")
            
            return df
            
        except Exception as e:
            logger.error(f"Error in load_data: {e}")
            raise
        finally:
            connection.close()

# Model trainer with FIXED XGBoost implementation
class ModelTrainer:
    def __init__(self):
        self.scalers = {}
        self.feature_importance = {}
    
    def train_single_model(self, X_train: pd.DataFrame, y_train: pd.Series,
                          X_test: pd.DataFrame, y_test: pd.Series,
                          model_type: str) -> tuple:
        """Train a single model with FIXED XGBoost handling"""
        try:
            # Ensure all features are numeric and finite
            X_train = X_train.astype(float)
            X_test = X_test.astype(float)
            y_train = y_train.astype(float)
            y_test = y_test.astype(float)
            
            # Replace any remaining infinite values
            X_train = X_train.replace([np.inf, -np.inf], 0)
            X_test = X_test.replace([np.inf, -np.inf], 0)
            X_train = X_train.fillna(0)
            X_test = X_test.fillna(0)
            
            # Ensure positive values for target
            y_train = y_train.clip(lower=0.001)
            y_test = y_test.clip(lower=0.001)
            
            if model_type == 'rf':
                model = RandomForestRegressor(
                    n_estimators=300,
                    max_depth=15,
                    min_samples_split=2,
                    min_samples_leaf=1,
                    max_features='sqrt',
                    random_state=42,
                    n_jobs=-1
                )
                model.fit(X_train, y_train)
                y_pred = model.predict(X_test)
                self.feature_importance[model_type] = dict(zip(X_train.columns, model.feature_importances_))
                
            elif model_type == 'xgb':
                # CRITICAL FIX: Simple XGBoost for small dataset
                original_columns = X_train.columns.tolist()
                cleaned_columns = clean_feature_names(original_columns)
                
                # Create mapping for later use
                feature_mapping = dict(zip(original_columns, cleaned_columns))
                
                # Create cleaned DataFrames with consistent column names
                X_train_clean = X_train.copy()
                X_test_clean = X_test.copy()
                X_train_clean.columns = cleaned_columns
                X_test_clean.columns = cleaned_columns
                
                # Log data statistics
                logger.info(f"XGBoost training data shape: {X_train_clean.shape}")
                logger.info(f"XGBoost target range: {y_train.min():.3f} - {y_train.max():.3f}")
                logger.info(f"XGBoost target mean: {y_train.mean():.3f}")
                logger.info(f"XGBoost target std: {y_train.std():.3f}")
                
                # ULTRA-SIMPLE XGBoost for small dataset (39 samples)
                model = xgb.XGBRegressor(
                    n_estimators=50,         # VERY FEW trees for small dataset
                    learning_rate=0.3,       # DEFAULT learning rate
                    max_depth=3,             # VERY shallow trees
                    subsample=1.0,           # USE ALL data (no subsampling)
                    colsample_bytree=1.0,    # USE ALL features
                    reg_alpha=0,             # NO regularization
                    reg_lambda=0,            # NO regularization
                    gamma=0,                 # NO gamma
                    min_child_weight=1,      # DEFAULT
                    objective='reg:squarederror',
                    tree_method='exact',     # More precise for small data
                    random_state=42,
                    n_jobs=1,                # Single thread for reproducibility
                    verbosity=1,             # Show training progress
                    enable_categorical=False,
                    validate_parameters=True
                )
                
                # Simple training without early stopping for small dataset
                logger.info("Training XGBoost with simple configuration...")
                model.fit(X_train_clean, y_train, verbose=True)
                
                # Make predictions
                y_pred = model.predict(X_test_clean)
                
                # Debug predictions extensively
                logger.info(f"XGBoost raw predictions: {y_pred}")
                logger.info(f"XGBoost predictions range: {y_pred.min():.3f} - {y_pred.max():.3f}")
                logger.info(f"XGBoost predictions mean: {y_pred.mean():.3f}")
                logger.info(f"XGBoost predictions std: {y_pred.std():.3f}")
                logger.info(f"XGBoost actual mean: {y_test.mean():.3f}")
                logger.info(f"XGBoost actual std: {y_test.std():.3f}")
                
                # Check for zero predictions
                zero_predictions = (y_pred == 0).sum()
                if zero_predictions > 0:
                    logger.warning(f"Found {zero_predictions} zero predictions out of {len(y_pred)}")
                
                # Check for problematic predictions
                if np.all(y_pred == 0):
                    logger.error("XGBoost produced ALL zero predictions!")
                    # Try to understand the model
                    logger.info(f"Model trees: {model.n_estimators}")
                    logger.info(f"Model booster: {model.get_booster().num_boosted_rounds()}")
                    
                    # Get feature importance
                    try:
                        importance = model.feature_importances_
                        logger.info(f"Feature importances shape: {importance.shape}")
                        logger.info(f"Feature importances sum: {importance.sum()}")
                        logger.info(f"Non-zero importances: {(importance > 0).sum()}")
                        if importance.sum() > 0:
                            top_features = np.argsort(importance)[-5:]
                            logger.info(f"Top 5 features: {[cleaned_columns[i] for i in top_features]}")
                    except Exception as imp_error:
                        logger.error(f"Could not get feature importance: {imp_error}")
                    
                    # Instead of fallback, try different approach
                    logger.warning("Trying alternative XGBoost configuration...")
                    
                    # Alternative model with different settings
                    alt_model = xgb.XGBRegressor(
                        n_estimators=10,
                        learning_rate=0.1,
                        max_depth=2,
                        subsample=1.0,
                        colsample_bytree=0.8,
                        reg_alpha=0,
                        reg_lambda=0.01,
                        random_state=42,
                        objective='reg:squarederror'
                    )
                    
                    alt_model.fit(X_train_clean, y_train)
                    y_pred_alt = alt_model.predict(X_test_clean)
                    
                    logger.info(f"Alternative model predictions: {y_pred_alt}")
                    
                    if not np.all(y_pred_alt == 0):
                        logger.info("Alternative model worked! Using alternative predictions.")
                        y_pred = y_pred_alt
                        model = alt_model
                    else:
                        logger.error("Both models failed. Using simple linear fallback.")
                        # Simple linear trend fallback
                        if len(y_train) > 1:
                            slope = (y_train.iloc[-1] - y_train.iloc[0]) / len(y_train)
                            y_pred = np.array([y_train.mean() + slope * i for i in range(len(y_test))])
                        else:
                            y_pred = np.full(len(y_test), y_train.mean())
                
                # Ensure predictions are reasonable and positive
                y_pred = np.maximum(y_pred, 0.1)  # At least 0.1, not 0
                
                # Store feature importance with original names
                try:
                    importance_clean = dict(zip(cleaned_columns, model.feature_importances_))
                    importance_original = {}
                    for orig, clean in feature_mapping.items():
                        if clean in importance_clean:
                            importance_original[orig] = importance_clean[clean]
                    self.feature_importance[model_type] = importance_original
                except Exception as e:
                    logger.warning(f"Could not store feature importance: {e}")
                    self.feature_importance[model_type] = {}
                
                # Store feature mapping for prediction phase
                model.feature_mapping = feature_mapping
                
            elif model_type == 'gb':
                # Use RobustScaler for better outlier handling
                scaler = RobustScaler()
                X_train_scaled = scaler.fit_transform(X_train)
                X_test_scaled = scaler.transform(X_test)
                self.scalers[model_type] = scaler
                
                model = GradientBoostingRegressor(
                    n_estimators=400,
                    learning_rate=0.08,
                    max_depth=6,
                    subsample=0.9,
                    max_features='sqrt',
                    random_state=42,
                    validation_fraction=0.2,
                    n_iter_no_change=30,
                    tol=1e-6
                )
                model.fit(X_train_scaled, y_train)
                y_pred = model.predict(X_test_scaled)
                self.feature_importance[model_type] = dict(zip(X_train.columns, model.feature_importances_))
                
            else:
                raise ValueError(f"Unknown model type: {model_type}")
            
            # Ensure predictions are positive
            y_pred = np.maximum(y_pred, 0)
            
            # Check for problematic predictions
            if np.all(y_pred == 0) or np.isnan(y_pred).any():
                logger.warning(f"{model_type} produced problematic predictions, using fallback")
                y_pred = np.full_like(y_test, y_train.mean())
            
            # Calculate metrics with safe conversion
            mse = mean_squared_error(y_test, y_pred)
            rmse = np.sqrt(mse)
            mae = mean_absolute_error(y_test, y_pred)
            
            # Safe MAPE calculation
            mask = y_test != 0
            if mask.sum() > 0:
                mape = np.mean(np.abs((y_test[mask] - y_pred[mask]) / y_test[mask])) * 100
            else:
                mape = 0.0
            
            r2 = r2_score(y_test, y_pred)
            
            metrics = {
                'MSE': safe_float_conversion(mse),
                'RMSE': safe_float_conversion(rmse),
                'MAE': safe_float_conversion(mae),
                'MAPE': safe_float_conversion(mape),
                'R2': safe_float_conversion(r2)
            }
            
            logger.info(f"{model_type} model trained - R2: {r2:.3f}, RMSE: {rmse:.3f}, MAPE: {mape:.1f}%")
            
            return model, metrics, y_pred
            
        except Exception as e:
            logger.error(f"Error training {model_type} model: {e}")
            raise
    
    def create_ensemble(self, models: Dict, X_test: pd.DataFrame, y_test: pd.Series,
                       ensemble_type: str) -> tuple:
        """Create ensemble predictions with improved error handling"""
        try:
            predictions = []
            weights = []
            
            if ensemble_type == 'rf_gb':
                model_types = ['rf', 'gb']
                type_weights = [0.6, 0.4]
            elif ensemble_type == 'rf_xgb':
                model_types = ['rf', 'xgb']
                type_weights = [0.5, 0.5]
            elif ensemble_type == 'gb_xgb':
                model_types = ['gb', 'xgb']
                type_weights = [0.4, 0.6]
            elif ensemble_type == 'rf_gb_xgb':
                model_types = ['rf', 'gb', 'xgb']
                type_weights = [0.4, 0.3, 0.3]
            else:
                raise ValueError(f"Unknown ensemble type: {ensemble_type}")
            
            for i, model_type in enumerate(model_types):
                if model_type in models:
                    if model_type == 'gb' and model_type in self.scalers:
                        X_test_scaled = self.scalers[model_type].transform(X_test)
                        pred = models[model_type].predict(X_test_scaled)
                    elif model_type == 'xgb':
                        # Handle XGBoost with feature mapping
                        if hasattr(models[model_type], 'feature_mapping'):
                            feature_mapping = models[model_type].feature_mapping
                            X_test_clean = X_test.copy()
                            original_cols = X_test.columns.tolist()
                            cleaned_cols = [feature_mapping.get(col, col) for col in original_cols]
                            X_test_clean.columns = cleaned_cols
                            pred = models[model_type].predict(X_test_clean)
                        else:
                            # Fallback: clean feature names again
                            X_test_clean = X_test.copy()
                            cleaned_cols = clean_feature_names(X_test.columns.tolist())
                            X_test_clean.columns = cleaned_cols
                            pred = models[model_type].predict(X_test_clean)
                    else:
                        pred = models[model_type].predict(X_test)
                    
                    # Ensure predictions are positive
                    pred = np.maximum(pred, 0)
                    predictions.append(pred)
                    weights.append(type_weights[i])
            
            if not predictions:
                raise ValueError(f"No models available for ensemble {ensemble_type}")
            
            # Weighted average predictions
            weights = np.array(weights) / np.sum(weights)
            ensemble_pred = np.average(predictions, axis=0, weights=weights)
            
            # Calculate metrics
            mse = mean_squared_error(y_test, ensemble_pred)
            rmse = np.sqrt(mse)
            mae = mean_absolute_error(y_test, ensemble_pred)
            
            # Safe MAPE calculation
            mask = y_test != 0
            if mask.sum() > 0:
                mape = np.mean(np.abs((y_test[mask] - ensemble_pred[mask]) / y_test[mask])) * 100
            else:
                mape = 0.0
            
            r2 = r2_score(y_test, ensemble_pred)
            
            metrics = {
                'MSE': safe_float_conversion(mse),
                'RMSE': safe_float_conversion(rmse),
                'MAE': safe_float_conversion(mae),
                'MAPE': safe_float_conversion(mape),
                'R2': safe_float_conversion(r2)
            }
            
            logger.info(f"{ensemble_type} ensemble created - R2: {r2:.3f}, RMSE: {rmse:.3f}, MAPE: {mape:.1f}%")
            
            return ensemble_pred, metrics
            
        except Exception as e:
            logger.error(f"Error creating ensemble {ensemble_type}: {e}")
            raise

# Model manager
class ModelManager:
    @staticmethod
    def save_model(model: Any, model_path: Path, metadata: Dict) -> None:
        """Save model and metadata"""
        model_path.parent.mkdir(parents=True, exist_ok=True)
        
        # Save model
        with open(model_path, 'wb') as f:
            pickle.dump(model, f)
        
        # Safe metadata conversion
        safe_metadata = safe_dict_conversion(metadata)
        
        # Save metadata
        metadata_path = model_path.parent / 'metadata.json'
        with open(metadata_path, 'w') as f:
            json.dump(safe_metadata, f, indent=2, default=str)
    
    @staticmethod
    def load_model(model_path: Path) -> tuple:
        """Load model and metadata"""
        if not model_path.exists():
            raise FileNotFoundError(f"Model not found: {model_path}")
        
        # Load model
        with open(model_path, 'rb') as f:
            model = pickle.load(f)
        
        # Load metadata
        metadata_path = model_path.parent / 'metadata.json'
        metadata = {}
        if metadata_path.exists():
            with open(metadata_path, 'r') as f:
                metadata = json.load(f)
        
        return model, metadata
    
    @staticmethod
    def get_model_path(resource_type: str, building_id: str, model_type: str) -> Path:
        """Get model file path"""
        safe_building_id = building_id.replace("-", "_") if building_id != "0" else "0"
        return MODELS_DIR / resource_type / f"building_{safe_building_id}" / f"{model_type}_model.pkl"

# Prediction helper with FIXED XGBoost handling
class Predictor:
    @staticmethod
    def create_future_features(last_data: pd.DataFrame, months_ahead: int,
                             resource_type: str) -> pd.DataFrame:
        """Create features for future months"""
        try:
            logger.info(f"Creating future features for {months_ahead} months")
            logger.info(f"Last data shape: {last_data.shape}")
            logger.info(f"Last data columns: {last_data.columns.tolist()}")
            
            if 'Date' not in last_data.columns:
                logger.error("'Date' column not found in last_data")
                raise ValueError("'Date' column not found in historical data")
            
            future_dates = []
            last_date = last_data['Date'].max()
            logger.info(f"Last date in data: {last_date}")
            
            for i in range(1, months_ahead + 1):
                # Calculate next month properly
                next_month = last_date.month + i
                next_year = last_date.year
                
                while next_month > 12:
                    next_month -= 12
                    next_year += 1
                
                future_dates.append(pd.Timestamp(year=next_year, month=next_month, day=1))
            
            logger.info(f"Generated {len(future_dates)} future dates")
            logger.info(f"First future date: {future_dates[0]}")
            logger.info(f"Last future date: {future_dates[-1]}")
            
            # Create future dataframe
            future_df = pd.DataFrame({'Date': future_dates})
            logger.info(f"Future df created with shape: {future_df.shape}")
            logger.info(f"Future df Date column type: {future_df['Date'].dtype}")
            logger.info(f"Sample future dates: {future_df['Date'].head().tolist()}")
            
            # Verify Date column
            if future_df['Date'].isna().any():
                logger.error("Found NaT values in Date column")
                raise ValueError("Invalid dates created in future dataframe")
            
            # Add basic features
            try:
                future_df = FeatureEngineer.create_features(future_df, resource_type)
                logger.info(f"After feature engineering: {future_df.shape}")
                logger.info(f"Columns after feature engineering: {future_df.columns.tolist()}")
                
                # Verify Date column still exists after feature engineering
                if 'Date' not in future_df.columns:
                    logger.error("Date column lost during feature engineering")
                    raise ValueError("Date column lost during feature engineering")
                    
            except Exception as fe_error:
                logger.error(f"Error in feature engineering: {fe_error}")
                raise
            
            # Fill future features with meaningful values based on historical data
            if len(last_data) > 0 and 'Usage' in last_data.columns:
                last_usage_values = last_data['Usage'].tail(24).values
                logger.info(f"Using {len(last_usage_values)} historical usage values")
                
                # Calculate seasonal patterns
                historical_monthly_avg = last_data.groupby(last_data['Date'].dt.month)['Usage'].mean()
                historical_overall_avg = last_data['Usage'].mean()
                
                if historical_overall_avg > 0:
                    seasonal_indexes = historical_monthly_avg / historical_overall_avg
                else:
                    seasonal_indexes = pd.Series(index=range(1, 13), data=1.0)
                
                logger.info(f"Seasonal indexes calculated: {seasonal_indexes.head()}")
                
                # Calculate trend
                if len(last_data) >= 12:
                    recent_trend = (last_data['Usage'].tail(6).mean() - last_data['Usage'].head(6).mean()) / len(last_data)
                else:
                    recent_trend = 0
                
                # Fill features for each future month
                for i, row_idx in enumerate(future_df.index):
                    current_month = future_df.loc[row_idx, 'Month']
                    base_seasonal = seasonal_indexes.get(current_month, 1.0)
                    
                    # Lag features with seasonal adjustment
                    for lag in [1, 2, 3, 6, 12, 24]:
                        if lag <= len(last_usage_values):
                            lag_value = last_usage_values[-lag] * base_seasonal
                            future_df.loc[row_idx, f'Usage_Lag{lag}'] = max(0, lag_value)
                        else:
                            avg_value = np.mean(last_usage_values) if len(last_usage_values) > 0 else 0
                            future_df.loc[row_idx, f'Usage_Lag{lag}'] = max(0, avg_value * base_seasonal)
                    
                    # Rolling features
                    for window in [3, 6, 12]:
                        if len(last_usage_values) >= window:
                            rolling_base = np.mean(last_usage_values[-window:])
                            future_df.loc[row_idx, f'RollingMean{window}'] = max(0, rolling_base * base_seasonal)
                            future_df.loc[row_idx, f'RollingStd{window}'] = np.std(last_usage_values[-window:])
                            future_df.loc[row_idx, f'RollingMin{window}'] = np.min(last_usage_values[-window:]) * base_seasonal
                            future_df.loc[row_idx, f'RollingMax{window}'] = np.max(last_usage_values[-window:]) * base_seasonal
                        else:
                            avg_value = np.mean(last_usage_values) if len(last_usage_values) > 0 else 0
                            future_df.loc[row_idx, f'RollingMean{window}'] = max(0, avg_value * base_seasonal)
                            future_df.loc[row_idx, f'RollingStd{window}'] = np.std(last_usage_values) if len(last_usage_values) > 0 else 0
                            future_df.loc[row_idx, f'RollingMin{window}'] = max(0, avg_value * base_seasonal * 0.8)
                            future_df.loc[row_idx, f'RollingMax{window}'] = max(0, avg_value * base_seasonal * 1.2)
                    
                    # Other features
                    future_df.loc[row_idx, 'SeasonalIndex'] = float(base_seasonal)
                    future_df.loc[row_idx, 'SeasonalStrength'] = abs(base_seasonal - 1.0)
                    
                    # Moving averages with trend
                    base_ma = np.mean(last_usage_values[-3:]) if len(last_usage_values) >= 3 else historical_overall_avg
                    future_df.loc[row_idx, 'MA_Short'] = max(0, base_ma * base_seasonal + recent_trend * i)
                    
                    base_ma_long = np.mean(last_usage_values[-12:]) if len(last_usage_values) >= 12 else historical_overall_avg
                    future_df.loc[row_idx, 'MA_Long'] = max(0, base_ma_long * base_seasonal)
                    
                    # Trend indicator
                    if future_df.loc[row_idx, 'MA_Long'] > 0:
                        future_df.loc[row_idx, 'TrendIndicator'] = (future_df.loc[row_idx, 'MA_Short'] - future_df.loc[row_idx, 'MA_Long']) / future_df.loc[row_idx, 'MA_Long']
                    else:
                        future_df.loc[row_idx, 'TrendIndicator'] = 0.0
                    
                    # Change rates (conservative estimates)
                    if len(last_usage_values) >= 2:
                        recent_monthly_change = (last_usage_values[-1] - last_usage_values[-2]) / max(last_usage_values[-2], 1)
                        future_df.loc[row_idx, 'MonthlyChange'] = max(-0.5, min(0.5, recent_monthly_change))
                    else:
                        future_df.loc[row_idx, 'MonthlyChange'] = 0.0
                    
                    if len(last_usage_values) >= 12:
                        recent_yearly_change = (last_usage_values[-1] - last_usage_values[-12]) / max(last_usage_values[-12], 1)
                        future_df.loc[row_idx, 'YearlyChange'] = max(-0.3, min(0.3, recent_yearly_change))
                    else:
                        future_df.loc[row_idx, 'YearlyChange'] = 0.0
                    
                    if len(last_usage_values) >= 3:
                        recent_quarterly_change = (last_usage_values[-1] - last_usage_values[-3]) / max(last_usage_values[-3], 1)
                        future_df.loc[row_idx, 'QuarterlyChange'] = max(-0.4, min(0.4, recent_quarterly_change))
                    else:
                        future_df.loc[row_idx, 'QuarterlyChange'] = 0.0
            
            # Final cleanup
            future_df = future_df.replace([np.inf, -np.inf], 0)
            future_df = future_df.fillna(0)
            
            # Ensure non-negative values for usage-related features
            usage_related_cols = [col for col in future_df.columns if 'Usage' in col or 'Rolling' in col or 'MA_' in col]
            for col in usage_related_cols:
                if col in future_df.columns:
                    future_df[col] = future_df[col].clip(lower=0)
            
            logger.info(f"Successfully created future features. Final shape: {future_df.shape}")
            logger.info(f"Final columns: {future_df.columns.tolist()}")
            
            return future_df
            
        except Exception as e:
            logger.error(f"Error creating future features: {e}")
            logger.error(f"Last data info: {last_data.info() if hasattr(last_data, 'info') else 'No info available'}")
            raise
    
    @staticmethod
    def predict_with_model(model_path: Path, X_test: pd.DataFrame,
                          model_type: str, scaler: Any = None) -> np.ndarray:
        """Make predictions with a single model - FIXED for XGBoost"""
        try:
            model, metadata = ModelManager.load_model(model_path)
            
            # Get trained feature columns
            trained_features = metadata.get('feature_columns', [])
            
            if trained_features:
                # Handle missing features
                missing_features = [col for col in trained_features if col not in X_test.columns]
                if missing_features:
                    logger.warning(f"Missing features for {model_type}: {missing_features[:5]}...")
                    for col in missing_features:
                        # Add missing features with appropriate defaults
                        if 'Lag' in col or 'Rolling' in col or 'MA_' in col:
                            X_test[col] = 0
                        elif 'Change' in col:
                            X_test[col] = 0.0
                        elif 'Seasonal' in col:
                            X_test[col] = 1.0
                        elif 'Trend' in col:
                            X_test[col] = 0.0
                        elif 'Is' in col:
                            X_test[col] = 0.0
                        else:
                            X_test[col] = 0.0
                
                # Remove extra features
                extra_features = [col for col in X_test.columns if col not in trained_features]
                if extra_features:
                    logger.warning(f"Removing extra features for {model_type}: {len(extra_features)} features")
                    X_test = X_test.drop(columns=extra_features)
                
                # Ensure correct column order
                X_test = X_test[trained_features]
            
            # Clean data
            X_test = X_test.astype(float)
            X_test = X_test.replace([np.inf, -np.inf], 0)
            X_test = X_test.fillna(0)
            
            # Model-specific prediction handling
            if model_type == 'xgb':
                # FIXED: Handle XGBoost feature names consistently
                if hasattr(model, 'feature_mapping'):
                    # Use stored feature mapping
                    feature_mapping = model.feature_mapping
                    original_cols = X_test.columns.tolist()
                    cleaned_cols = [feature_mapping.get(col, col) for col in original_cols]
                else:
                    # Fallback: recreate mapping
                    original_cols = X_test.columns.tolist()
                    cleaned_cols = clean_feature_names(original_cols)
                
                X_test_clean = X_test.copy()
                X_test_clean.columns = cleaned_cols
                
                logger.info(f"XGBoost prediction with {len(cleaned_cols)} features")
                predictions = model.predict(X_test_clean)
                
            elif model_type == 'gb' and scaler is not None:
                X_test_scaled = scaler.transform(X_test)
                predictions = model.predict(X_test_scaled)
                
            else:
                predictions = model.predict(X_test)
            
            # Ensure non-negative predictions
            predictions = np.maximum(predictions, 0)
            
            # Validate predictions
            if np.all(predictions == 0) or np.isnan(predictions).any():
                logger.warning(f"{model_type} produced problematic predictions, using smart fallback")
                # Use a reasonable fallback based on feature statistics and historical data
                if 'Usage_Lag1' in X_test.columns and X_test['Usage_Lag1'].mean() > 0:
                    fallback_value = X_test['Usage_Lag1'].mean()
                    logger.info(f"Using lag1 mean as fallback: {fallback_value}")
                elif 'RollingMean3' in X_test.columns and X_test['RollingMean3'].mean() > 0:
                    fallback_value = X_test['RollingMean3'].mean()
                    logger.info(f"Using rolling mean as fallback: {fallback_value}")
                else:
                    fallback_value = 100000.0  # Reasonable default for electricity usage
                    logger.info(f"Using default fallback: {fallback_value}")
                
                # Create predictions with some seasonal variation
                seasonal_factors = [1.2, 1.1, 0.9, 0.8, 0.7, 0.8, 1.3, 1.4, 1.0, 0.9, 1.0, 1.1]
                predictions = np.array([fallback_value * seasonal_factors[i % 12] for i in range(len(X_test))])
                logger.info(f"Generated fallback predictions: {predictions}")
            
            # Ensure minimum reasonable values
            predictions = np.maximum(predictions, 1.0)  # At least 1 unit of usage
            
            logger.info(f"{model_type} final predictions: min={predictions.min():.2f}, max={predictions.max():.2f}, mean={predictions.mean():.2f}")
            
            return predictions
            
        except Exception as e:
            logger.error(f"Error making predictions with {model_type}: {e}")
            raise

# API Routes
@app.get("/")
async def root():
    return {"message": "Energy Consumption Prediction API", "version": "1.0.0"}

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    try:
        connection = get_db_connection()
        cursor = connection.cursor()
        cursor.execute("SELECT 1")
        result = cursor.fetchone()
        connection.close()
        
        return {
            "status": "healthy",
            "database": "connected",
            "environment": ENVIRONMENT,
            "debug": DEBUG,
            "database_host": DB_CONFIG['host'],
            "database_name": DB_CONFIG['database'],
            "models_directory": str(MODELS_DIR),
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Health check failed: {e}")
        return {
            "status": "unhealthy",
            "database": "disconnected",
            "error": str(e),
            "environment": ENVIRONMENT,
            "timestamp": datetime.now().isoformat()
        }

@app.post("/train", response_model=TrainResponse)
async def train_models(request: TrainRequest, background_tasks: BackgroundTasks):
    """Train models for specified resource type and building"""
    try:
        # Validate inputs
        if request.resource_type not in RESOURCE_MAPPING:
            raise HTTPException(status_code=400, detail=f"Invalid resource type: {request.resource_type}")
        
        logger.info(f"Training request: {request.resource_type}, building {request.building_id}")
        logger.info(f"Model types: {request.model_types}")
        logger.info(f"Ensemble types: {request.ensemble_types}")
        
        # Load data
        df = DataLoader.load_data(request.resource_type, request.building_id)
        
        # Check minimum data requirement
        if len(df) < 13:
            raise HTTPException(
                status_code=400,
                detail=f"Insufficient data. Found {len(df)} records, minimum 13 required."
            )
        
        # Feature engineering
        logger.info("Creating features...")
        df = FeatureEngineer.create_features(df, request.resource_type)
        feature_cols = FeatureEngineer.get_feature_columns(df, request.resource_type)
        
        logger.info(f"Created {len(feature_cols)} features")
        
        # Data splitting strategy
        if len(df) >= 36:  # 3+ years
            train_data = df.iloc[:-12].copy()
            test_data = df.iloc[-12:].copy()
        elif len(df) >= 24:  # 2+ years
            train_data = df.iloc[:-6].copy()
            test_data = df.iloc[-6:].copy()
        else:
            test_size = max(1, min(6, len(df) // 5))
            train_data = df.iloc[:-test_size].copy()
            test_data = df.iloc[-test_size:].copy()
        
        X_train = train_data[feature_cols]
        y_train = train_data['Usage']
        X_test = test_data[feature_cols]
        y_test = test_data['Usage']
        
        logger.info(f"Training: {len(train_data)} records, Test: {len(test_data)} records")
        logger.info(f"Features: {X_train.shape}")
        
        # Train models
        trainer = ModelTrainer()
        models_trained = []
        all_metrics = {}
        trained_models = {}
        
        # Train individual models
        for model_type in request.model_types:
            if model_type in MODEL_TYPES:
                try:
                    logger.info(f"Training {model_type} model...")
                    model, metrics, y_pred = trainer.train_single_model(
                        X_train, y_train, X_test, y_test, model_type
                    )
                    
                    # Save model
                    model_path = ModelManager.get_model_path(
                        request.resource_type, request.building_id, model_type
                    )
                    metadata = {
                        'resource_type': request.resource_type,
                        'building_id': request.building_id,
                        'model_type': model_type,
                        'trained_at': datetime.now().isoformat(),
                        'metrics': metrics,
                        'data_points': len(df),
                        'feature_columns': feature_cols,
                        'train_size': len(train_data),
                        'test_size': len(test_data)
                    }
                    
                    # Save scaler if exists
                    if model_type in trainer.scalers:
                        scaler_path = model_path.parent / f"{model_type}_scaler.pkl"
                        scaler_path.parent.mkdir(parents=True, exist_ok=True)
                        with open(scaler_path, 'wb') as f:
                            pickle.dump(trainer.scalers[model_type], f)
                        metadata['has_scaler'] = True
                    
                    ModelManager.save_model(model, model_path, metadata)
                    models_trained.append(model_type)
                    all_metrics[model_type] = metrics
                    trained_models[model_type] = model
                    
                    logger.info(f" {model_type} trained: R2={metrics['R2']:.3f}")
                    
                except Exception as e:
                    logger.error(f" Failed to train {model_type}: {e}")
                    continue
        
        # Create ensembles
        for ensemble_type in request.ensemble_types:
            if ensemble_type in ENSEMBLE_TYPES:
                try:
                    logger.info(f"Creating {ensemble_type} ensemble...")
                    ensemble_pred, ensemble_metrics = trainer.create_ensemble(
                        trained_models, X_test, y_test, ensemble_type
                    )
                    
                    # Save ensemble metadata
                    ensemble_path = ModelManager.get_model_path(
                        request.resource_type, request.building_id, ensemble_type
                    )
                    ensemble_metadata = {
                        'resource_type': request.resource_type,
                        'building_id': request.building_id,
                        'model_type': ensemble_type,
                        'ensemble_components': ensemble_type.split('_'),
                        'trained_at': datetime.now().isoformat(),
                        'metrics': ensemble_metrics,
                        'data_points': len(df),
                        'feature_columns': feature_cols,
                        'train_size': len(train_data),
                        'test_size': len(test_data)
                    }
                    
                    ensemble_path.parent.mkdir(parents=True, exist_ok=True)
                    metadata_path = ensemble_path.parent / f'{ensemble_type}_metadata.json'
                    with open(metadata_path, 'w') as f:
                        json.dump(safe_dict_conversion(ensemble_metadata), f, indent=2, default=str)
                    
                    models_trained.append(ensemble_type)
                    all_metrics[ensemble_type] = ensemble_metrics
                    
                    logger.info(f" {ensemble_type} ensemble: R2={ensemble_metrics['R2']:.3f}")
                    
                except Exception as e:
                    logger.warning(f" Failed to create {ensemble_type} ensemble: {e}")
        
        if not models_trained:
            raise HTTPException(status_code=500, detail="No models were successfully trained")
        
        return TrainResponse(
            success=True,
            message=f"Successfully trained {len(models_trained)} models",
            models_trained=models_trained,
            metrics=safe_dict_conversion(all_metrics),
            data_info=safe_dict_conversion({
                'total_records': len(df),
                'training_records': len(train_data),
                'test_records': len(test_data),
                'features_count': len(feature_cols),
                'date_range': f"{df['Date'].min()} to {df['Date'].max()}"
            })
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Training error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/predict", response_model=PredictResponse)
async def predict_consumption(request: PredictRequest):
    """Predict future consumption using trained models"""
    try:
        # Validate inputs
        if request.resource_type not in RESOURCE_MAPPING:
            raise HTTPException(status_code=400, detail=f"Invalid resource type: {request.resource_type}")
        
        # Check if model exists
        model_path = ModelManager.get_model_path(
            request.resource_type, request.building_id, request.model_type
        )
        
        # For ensemble models, check metadata file
        if request.model_type in ENSEMBLE_TYPES:
            metadata_path = model_path.parent / f'{request.model_type}_metadata.json'
            if not metadata_path.exists():
                raise HTTPException(
                    status_code=404,
                    detail=f"Ensemble model {request.model_type} not found"
                )
        else:
            if not model_path.exists():
                raise HTTPException(
                    status_code=404,
                    detail=f"Model {request.model_type} not found"
                )
        
        # Load historical data
        df = DataLoader.load_data(request.resource_type, request.building_id)
        if len(df) < 13:
            raise HTTPException(
                status_code=400,
                detail="Insufficient historical data for predictions"
            )
        
        # Create features for historical data
        df = FeatureEngineer.create_features(df, request.resource_type)
        
        # Create future features
        try:
            future_df = Predictor.create_future_features(df, request.months_ahead, request.resource_type)
            logger.info(f"Successfully created future features. Shape: {future_df.shape}")
        except Exception as e:
            logger.error(f"Error creating future features: {e}")
            raise HTTPException(status_code=500, detail=f"Error creating future features: {str(e)}")
        
        # Get trained features
        if request.model_type in ENSEMBLE_TYPES:
            metadata_path = model_path.parent / f'{request.model_type}_metadata.json'
            with open(metadata_path, 'r') as f:
                ensemble_metadata = json.load(f)
            trained_features = ensemble_metadata.get('feature_columns', [])
            
            if not trained_features:
                # Get from component model
                component_models = ensemble_metadata['ensemble_components']
                for component in component_models:
                    component_path = ModelManager.get_model_path(
                        request.resource_type, request.building_id, component
                    )
                    if component_path.exists():
                        _, comp_metadata = ModelManager.load_model(component_path)
                        trained_features = comp_metadata.get('feature_columns', [])
                        if trained_features:
                            break
        else:
            _, metadata = ModelManager.load_model(model_path)
            trained_features = metadata.get('feature_columns', [])
        
        # Prepare features
        if trained_features:
            # CRITICAL FIX: Ensure Date column is preserved
            # Add missing features (except Date)
            missing_features = [col for col in trained_features if col not in future_df.columns and col != 'Date']
            if missing_features:
                logger.warning(f"Adding {len(missing_features)} missing features")
                for col in missing_features:
                    future_df[col] = 0
            
            # Remove extra features (except Date)
            extra_features = [col for col in future_df.columns if col not in trained_features and col != 'Date']
            if extra_features:
                logger.warning(f"Removing {len(extra_features)} extra features (preserving Date)")
                future_df = future_df.drop(columns=extra_features)
            
            # Create X_future without Date column for prediction
            feature_columns_for_prediction = [col for col in trained_features if col in future_df.columns and col != 'Date']
            X_future = future_df[feature_columns_for_prediction]
            logger.info(f"Using {len(feature_columns_for_prediction)} features for prediction (excluding Date)")
        else:
            # If no trained features info, use all except Date
            feature_columns = [col for col in future_df.columns if col != 'Date']
            X_future = future_df[feature_columns]
        
        # Clean data
        X_future = X_future.replace([np.inf, -np.inf], 0)
        X_future = X_future.fillna(0)
        X_future = X_future.astype(float)
        
        logger.info(f"Prediction features shape: {X_future.shape}")
        
        # Make predictions
        predictions = []
        model_info = {}
        
        if request.model_type in ENSEMBLE_TYPES:
            # Handle ensemble predictions
            metadata_path = model_path.parent / f'{request.model_type}_metadata.json'
            with open(metadata_path, 'r') as f:
                ensemble_metadata = json.load(f)
            
            ensemble_predictions = []
            component_models = ensemble_metadata['ensemble_components']
            
            for component in component_models:
                component_path = ModelManager.get_model_path(
                    request.resource_type, request.building_id, component
                )
                if component_path.exists():
                    # Load scaler if needed
                    scaler = None
                    if component == 'gb':
                        scaler_path = component_path.parent / f"{component}_scaler.pkl"
                        if scaler_path.exists():
                            with open(scaler_path, 'rb') as f:
                                scaler = pickle.load(f)
                    
                    component_pred = Predictor.predict_with_model(
                        component_path, X_future, component, scaler
                    )
                    ensemble_predictions.append(component_pred)
                    logger.info(f"Component {component}: {component_pred.mean():.2f}")
            
            if not ensemble_predictions:
                raise HTTPException(
                    status_code=404,
                    detail=f"No component models found for ensemble {request.model_type}"
                )
            
            # Weighted average
            weights = [0.4, 0.3, 0.3] if len(ensemble_predictions) == 3 else [0.5, 0.5]
            weights = weights[:len(ensemble_predictions)]
            weights = np.array(weights) / np.sum(weights)
            
            final_predictions = np.average(ensemble_predictions, axis=0, weights=weights)
            model_info = ensemble_metadata
            
            logger.info(f"Ensemble predictions: {final_predictions.mean():.2f}")
            
        else:
            # Handle single model predictions
            scaler = None
            if request.model_type == 'gb':
                scaler_path = model_path.parent / f"{request.model_type}_scaler.pkl"
                if scaler_path.exists():
                    with open(scaler_path, 'rb') as f:
                        scaler = pickle.load(f)
            
            final_predictions = Predictor.predict_with_model(
                model_path, X_future, request.model_type, scaler
            )
            
            _, metadata = ModelManager.load_model(model_path)
            model_info = metadata
        
        # Ensure reasonable predictions
        final_predictions = np.maximum(final_predictions, 0)
        
        # Format predictions with better error handling
        try:
            logger.info(f"Starting prediction formatting...")
            logger.info(f"Final predictions shape: {final_predictions.shape if hasattr(final_predictions, 'shape') else len(final_predictions)}")
            logger.info(f"Future df shape: {future_df.shape}")
            logger.info(f"Future df columns: {future_df.columns.tolist()}")
            
            # Check if Date column exists
            if 'Date' not in future_df.columns:
                logger.error("Date column missing from future_df")
                logger.error(f"Available columns: {future_df.columns.tolist()}")
                raise ValueError("Date column missing from future dataframe")
            
            logger.info(f"Date column type: {type(future_df['Date'].iloc[0])}")
            logger.info(f"First few dates: {future_df['Date'].head().tolist()}")
            
            for i, pred in enumerate(final_predictions):
                if i < len(future_df):
                    try:
                        future_date = future_df.iloc[i]['Date']
                        logger.info(f"Processing prediction {i}: date={future_date}, pred={pred}")
                        
                        # Ensure future_date is a valid datetime
                        if pd.isna(future_date):
                            logger.warning(f"NaT date at index {i}, skipping")
                            continue
                            
                        predictions.append({
                            'date': future_date.strftime('%Y-%m'),
                            'predicted_usage': safe_float_conversion(pred),
                            'month': int(future_date.month),
                            'year': int(future_date.year)
                        })
                    except Exception as date_error:
                        logger.error(f"Error processing date at index {i}: {date_error}")
                        logger.error(f"Date value: {future_df.iloc[i]['Date']}")
                        logger.error(f"Date type: {type(future_df.iloc[i]['Date'])}")
                        raise
                else:
                    # Fallback if future_df is shorter than predictions
                    logger.warning(f"Prediction index {i} exceeds future_df length, creating fallback date")
                    try:
                        if 'Date' in future_df.columns and len(future_df) > 0:
                            last_date = future_df.iloc[-1]['Date']
                            next_month = last_date.month + (i - len(future_df) + 1)
                            next_year = last_date.year
                            while next_month > 12:
                                next_month -= 12
                                next_year += 1
                        else:
                            # Ultimate fallback - use current date
                            from datetime import datetime
                            current_date = datetime.now()
                            next_month = current_date.month + i
                            next_year = current_date.year
                            while next_month > 12:
                                next_month -= 12
                                next_year += 1
                        
                        predictions.append({
                            'date': f"{next_year}-{next_month:02d}",
                            'predicted_usage': safe_float_conversion(pred),
                            'month': next_month,
                            'year': next_year
                        })
                    except Exception as fallback_error:
                        logger.error(f"Error in fallback date creation: {fallback_error}")
                        raise
                        
        except Exception as e:
            logger.error(f"Error formatting predictions: {e}")
            logger.error(f"Future df info:")
            if hasattr(future_df, 'info'):
                import io
                buffer = io.StringIO()
                future_df.info(buf=buffer)
                logger.error(buffer.getvalue())
            logger.error(f"Future df head: {future_df.head() if hasattr(future_df, 'head') else 'No head'}")
            raise HTTPException(status_code=500, detail=f"Error formatting predictions: {str(e)}")
        
        logger.info(f"Generated {len(predictions)} predictions successfully")
        
        return PredictResponse(
            success=True,
            predictions=predictions,
            model_info=safe_dict_conversion({
                'model_type': request.model_type,
                'resource_type': request.resource_type,
                'building_id': request.building_id,
                'trained_at': model_info.get('trained_at', 'Unknown'),
                'metrics': model_info.get('metrics', {}),
                'months_predicted': request.months_ahead,
                'feature_count': len(trained_features) if trained_features else 0,
                'prediction_range': f"{final_predictions.min():.2f} - {final_predictions.max():.2f}"
            })
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Prediction error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/models", response_model=List[ModelInfo])
async def list_models():
    """List all trained models"""
    models = []
    try:
        for resource_type in RESOURCE_MAPPING.keys():
            resource_dir = MODELS_DIR / resource_type
            if not resource_dir.exists():
                continue
            
            for building_dir in resource_dir.iterdir():
                if not building_dir.is_dir():
                    continue
                
                # Extract building_id from directory name
                dir_name = building_dir.name
                if dir_name.startswith('building_'):
                    building_id_part = dir_name[9:]
                    if building_id_part == "0":
                        building_id = "0"
                    else:
                        building_id = building_id_part.replace("_", "-")
                else:
                    continue
                
                # Check individual models
                for model_type in MODEL_TYPES:
                    model_path = building_dir / f"{model_type}_model.pkl"
                    if model_path.exists():
                        try:
                            _, metadata = ModelManager.load_model(model_path)
                            models.append(ModelInfo(
                                resource_type=resource_type,
                                building_id=building_id,
                                model_type=model_type,
                                trained_at=metadata.get('trained_at', 'Unknown'),
                                metrics=safe_dict_conversion(metadata.get('metrics', {})),
                                data_points=metadata.get('data_points', 0)
                            ))
                        except Exception as e:
                            logger.warning(f"Error loading model metadata: {e}")
                
                # Check ensemble models
                for ensemble_type in ENSEMBLE_TYPES:
                    metadata_path = building_dir / f'{ensemble_type}_metadata.json'
                    if metadata_path.exists():
                        try:
                            with open(metadata_path, 'r') as f:
                                metadata = json.load(f)
                            models.append(ModelInfo(
                                resource_type=resource_type,
                                building_id=building_id,
                                model_type=ensemble_type,
                                trained_at=metadata.get('trained_at', 'Unknown'),
                                metrics=safe_dict_conversion(metadata.get('metrics', {})),
                                data_points=metadata.get('data_points', 0)
                            ))
                        except Exception as e:
                            logger.warning(f"Error loading ensemble metadata: {e}")
    
    except Exception as e:
        logger.error(f"Error listing models: {e}")
        raise HTTPException(status_code=500, detail=str(e))
    
    return models

@app.get("/models/{resource_type}/{building_id}")
async def get_building_models(resource_type: str, building_id: str):
    """Get all models for a specific resource type and building"""
    if resource_type not in RESOURCE_MAPPING:
        raise HTTPException(status_code=400, detail=f"Invalid resource type: {resource_type}")
    
    models = []
    safe_building_id = building_id.replace("-", "_") if building_id != "0" else "0"
    building_dir = MODELS_DIR / resource_type / f"building_{safe_building_id}"
    
    if not building_dir.exists():
        raise HTTPException(
            status_code=404,
            detail=f"No models found for {resource_type}, building {building_id}"
        )
    
    try:
        # Individual models
        for model_type in MODEL_TYPES:
            model_path = building_dir / f"{model_type}_model.pkl"
            if model_path.exists():
                _, metadata = ModelManager.load_model(model_path)
                models.append({
                    'model_type': model_type,
                    'type': 'individual',
                    'trained_at': metadata.get('trained_at', 'Unknown'),
                    'metrics': safe_dict_conversion(metadata.get('metrics', {})),
                    'data_points': metadata.get('data_points', 0)
                })
        
        # Ensemble models
        for ensemble_type in ENSEMBLE_TYPES:
            metadata_path = building_dir / f'{ensemble_type}_metadata.json'
            if metadata_path.exists():
                with open(metadata_path, 'r') as f:
                    metadata = json.load(f)
                models.append({
                    'model_type': ensemble_type,
                    'type': 'ensemble',
                    'components': metadata.get('ensemble_components', []),
                    'trained_at': metadata.get('trained_at', 'Unknown'),
                    'metrics': safe_dict_conversion(metadata.get('metrics', {})),
                    'data_points': metadata.get('data_points', 0)
                })
        
        if not models:
            raise HTTPException(
                status_code=404,
                detail=f"No trained models found for {resource_type}, building {building_id}"
            )
        
        return {
            'resource_type': resource_type,
            'building_id': building_id,
            'models': models,
            'total_models': len(models)
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting building models: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.delete("/models/{resource_type}/{building_id}")
async def delete_building_models(resource_type: str, building_id: str):
    """Delete all models for a specific resource type and building"""
    if resource_type not in RESOURCE_MAPPING:
        raise HTTPException(status_code=400, detail=f"Invalid resource type: {resource_type}")
    
    safe_building_id = building_id.replace("-", "_") if building_id != "0" else "0"
    building_dir = MODELS_DIR / resource_type / f"building_{safe_building_id}"
    
    if not building_dir.exists():
        raise HTTPException(
            status_code=404,
            detail=f"No models found for {resource_type}, building {building_id}"
        )
    
    try:
        import shutil
        shutil.rmtree(building_dir)
        return {
            'success': True,
            'message': f"Successfully deleted all models for {resource_type}, building {building_id}"
        }
    except Exception as e:
        logger.error(f"Error deleting models: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/data-info/{resource_type}")
async def get_data_info(resource_type: str, building_id: Optional[str] = "0"):
    """Get data information for a resource type and building"""
    if resource_type not in RESOURCE_MAPPING:
        raise HTTPException(status_code=400, detail=f"Invalid resource type: {resource_type}")
    
    try:
        df = DataLoader.load_data(resource_type, building_id)
        
        usage_stats = {
            'min': safe_float_conversion(df['Usage'].min()),
            'max': safe_float_conversion(df['Usage'].max()),
            'mean': safe_float_conversion(df['Usage'].mean()),
            'std': safe_float_conversion(df['Usage'].std())
        }
        
        # Create monthly data safely
        monthly_data = {}
        for date, usage in df.groupby(df['Date'].dt.strftime('%Y-%m'))['Usage'].sum().items():
            monthly_data[date] = safe_float_conversion(usage)
        
        return {
            'resource_type': resource_type,
            'building_id': building_id,
            'total_records': len(df),
            'date_range': {
                'start': df['Date'].min().strftime('%Y-%m-%d'),
                'end': df['Date'].max().strftime('%Y-%m-%d')
            },
            'usage_stats': usage_stats,
            'sufficient_for_training': len(df) >= 13,
            'monthly_data': monthly_data
        }
        
    except Exception as e:
        logger.error(f"Error getting data info: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/available-buildings/{resource_type}")
async def get_available_buildings(resource_type: str):
    """Get available buildings with sufficient data for training"""
    if resource_type not in RESOURCE_MAPPING:
        raise HTTPException(status_code=400, detail=f"Invalid resource type: {resource_type}")
    
    table_name = RESOURCE_MAPPING[resource_type]
    connection = get_db_connection()
    
    try:
        cursor = connection.cursor()
        query = f"""
            SELECT
                BuildingId,
                COUNT(DISTINCT YEAR(`Date`), MONTH(`Date`)) as monthly_records,
                SUM(CASE WHEN `Usage` > 0 THEN 1 ELSE 0 END) as non_zero_records,
                AVG(CASE WHEN `Usage` > 0 THEN `Usage` ELSE NULL END) as avg_usage,
                MIN(`Date`) as min_date,
                MAX(`Date`) as max_date
            FROM {table_name}
            WHERE `Usage` > 0 AND `Date` IS NOT NULL
            GROUP BY BuildingId
            HAVING COUNT(DISTINCT YEAR(`Date`), MONTH(`Date`)) >= 13
            ORDER BY COUNT(DISTINCT YEAR(`Date`), MONTH(`Date`)) DESC
        """
        cursor.execute(query)
        buildings = cursor.fetchall()
        
        # Safe conversion for buildings data
        safe_buildings = []
        for building in buildings:
            safe_building = {}
            for key, value in building.items():
                if isinstance(value, (int, float)):
                    safe_building[key] = safe_float_conversion(value)
                else:
                    safe_building[key] = value
            safe_buildings.append(safe_building)
        
        return {
            'resource_type': resource_type,
            'available_buildings': safe_buildings,
            'total_buildings': len(safe_buildings)
        }
        
    except Exception as e:
        logger.error(f"Error getting available buildings: {e}")
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        connection.close()

if __name__ == "__main__":
    import uvicorn
    
    # Get configuration from environment
    host = os.getenv('API_HOST', '0.0.0.0')
    port = int(os.getenv('API_PORT', 8000))
    workers = int(os.getenv('API_WORKERS', 1))
    
    logger.info(f"Starting server on {host}:{port} with {workers} workers")
    
    if ENVIRONMENT == 'development':
        # Development mode with auto-reload
        uvicorn.run(
            "main:app",
            host=host,
            port=port,
            reload=True,
            log_level="info" if DEBUG else "warning"
        )
    else:
        # Production mode
        uvicorn.run(
            app,
            host=host,
            port=port,
            workers=workers,
            log_level="info" if DEBUG else "warning"
        )
